{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0d7cbb",
   "metadata": {
    "id": "bf0d7cbb"
   },
   "source": [
    "### Dataset Description\n",
    "The dataset contains bird images, divided into train and test splits. The images are inside test_images and train_images folders.\n",
    "\n",
    "The labels of the training images are inside train_images.csv file. In this file, the first column is image_path and the second one is the label (1 - 200). The test_images_samples.csv includes a row id with a dummy label. The final goal of the challenge is to change the label column to the predicted label.\n",
    "\n",
    "The class_names.npy is a dictionary including the name of each label. Load the file using the following code: np.load(\"class_names.npy\", allow_pickle=True).item()\n",
    "\n",
    "The structure of the final submission should be exactly the same as the test_images_samples.csv! Otherwise, it will fail.\n",
    "\n",
    "Files\n",
    "\n",
    "- train_images - the training images\n",
    "- test_images - the test images\n",
    "- test_images_sample.csv - a sample submission file in the correct format\n",
    "- test_images_path.csv - path to test file images\n",
    "- train_images.csv - supplemental information about the data\n",
    "- class_names.npy - this file includes the name of each label\n",
    "- attributes.npy - this file includes the attributes which are extra information for each class.\n",
    "- attributes.txt - this file includes the attribute names which are extra information for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16124d83",
   "metadata": {
    "id": "16124d83"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h8IjUfeZFEgz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8IjUfeZFEgz",
    "outputId": "cef7b1a4-6d55-40e3-f639-70ab32e41982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eGRcW_yG2Cm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eGRcW_yG2Cm",
    "outputId": "4d2d3c5d-a470-4f95-e38e-2f54aa1cc01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wd changed to: /content/drive/MyDrive/UvA Data Science/AMS_feathers_in_focus-main\n"
     ]
    }
   ],
   "source": [
    "# base_data_path = '/content/drive/MyDrive/UvA Data Science/AMS_feathers_in_focus-main'\n",
    "\n",
    "# #change gdrive wd\n",
    "# os.chdir(base_data_path)\n",
    "# print(f\"wd changed to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1023737",
   "metadata": {
    "id": "f1023737"
   },
   "source": [
    "**Easy to find parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a9424e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06a9424e",
    "outputId": "e064eb58-7d0a-4477-9a40-52e17acfd49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "max_lr = 0.003\n",
    "weight_decay = 0.0004\n",
    "num_epochs = 50\n",
    "num_classes = 200\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "val_split = 0.2\n",
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111c4c0",
   "metadata": {
    "id": "6111c4c0"
   },
   "source": [
    "### Setting up dataset and dataloaders\n",
    "creating train and validation set (80:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d35a809",
   "metadata": {
    "id": "6d35a809"
   },
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, img_col_idx, label_col_idx, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.img_col_idx = img_col_idx\n",
    "        self.label_col_idx = label_col_idx\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = str(self.data.iloc[idx, self.img_col_idx])\n",
    "        clean_filename = filename.lstrip('/').lstrip('\\\\')\n",
    "        img_path = os.path.join(self.root_dir, clean_filename)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except (FileNotFoundError, OSError):\n",
    "            print(f\"Could not open {img_path}, using black image.\")\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "\n",
    "        # Raw CSV is 1-200. We subtract 1 to get 0-199 for PyTorch.\n",
    "        raw_label = int(self.data.iloc[idx, self.label_col_idx])\n",
    "        label = raw_label - 1\n",
    "\n",
    "        # Transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b7c9e0",
   "metadata": {
    "id": "98b7c9e0"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02),\n",
    "    transforms.RandomAffine(\n",
    "        degrees=15,\n",
    "        translate=(0.1, 0.1),\n",
    "        scale=(0.8, 1.2),\n",
    "        shear=10\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        (0.485, 0.456, 0.406),\n",
    "        (0.229, 0.224, 0.225)\n",
    "    ),\n",
    "    transforms.RandomErasing(p=0.15)\n",
    "])\n",
    "\n",
    "# 2. Validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5de6d",
   "metadata": {
    "id": "cee5de6d"
   },
   "source": [
    "**Dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d5eac62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d5eac62",
    "outputId": "24f67ce7-bd34-4807-dc76-1d1e5654e9f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3140\n",
      "Validation set: 786\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "full_train_dataset = BirdDataset('train_images.csv', 'train_images', 0, 1, transform=train_transform)\n",
    "full_val_dataset   = BirdDataset('train_images.csv', 'train_images', 0, 1, transform=val_transform)\n",
    "\n",
    "labels = full_train_dataset.data.iloc[:, 1].values - 1\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=int(1 / val_split),\n",
    "    shuffle=True,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Take first fold\n",
    "for train_idx, val_idx in skf.split(np.zeros(len(labels)), labels):\n",
    "    break\n",
    "\n",
    "train_dataset = Subset(full_train_dataset, train_idx)\n",
    "val_dataset   = Subset(full_val_dataset,   val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training set: {len(train_dataset)}\")\n",
    "print(f\"Validation set: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2209b84",
   "metadata": {
    "id": "a2209b84"
   },
   "source": [
    "**Setting up test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d336deb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "d336deb0",
    "outputId": "7ab13262-311c-4457-ea1e-e8db0cecaa39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 4000 images to predict.\n"
     ]
    }
   ],
   "source": [
    "test_dataset  = BirdDataset('test_images_path.csv', 'test_images', 1, 2, transform=val_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Test set: {len(test_dataset)} images to predict.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea65d5e-2bcc-4fc8-bbbe-71d4ef20c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([32, 3, 224, 224])\n",
      "Labels shape: torch.Size([32])\n",
      "First 5 labels: tensor([0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "test_iter = iter(test_loader)\n",
    "images, labels = next(test_iter)\n",
    "\n",
    "print(\"Batch shape:\", images.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"First 5 labels:\", labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704c784",
   "metadata": {
    "id": "3704c784"
   },
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "FzW6tm4rSJCp",
   "metadata": {
    "id": "FzW6tm4rSJCp"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dw = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, padding=1, groups=in_channels, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.pw = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, 1, bias=False) \\\n",
    "            if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dw(x)\n",
    "        out = self.pw(out)\n",
    "        out = out + 0.5 * self.shortcut(x)\n",
    "        return self.activation(out)\n",
    "\n",
    "\n",
    "class mobile_vgg(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Block(32, 32),\n",
    "            Block(32, 64)\n",
    "        )\n",
    "        self.down1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.stage2 = nn.Sequential(\n",
    "            Block(64, 64),\n",
    "            Block(64, 128)\n",
    "        )\n",
    "        self.down2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.stage3 = nn.Sequential(\n",
    "            Block(128, 128),\n",
    "            Block(128, 256)\n",
    "        )\n",
    "        self.down3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.stage4 = nn.Sequential(\n",
    "            Block(256, 256),\n",
    "            Block(256, 512)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.down3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "IKZ8cnXEU47T",
   "metadata": {
    "id": "IKZ8cnXEU47T"
   },
   "outputs": [],
   "source": [
    "model = mobile_vgg(num_classes=num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=num_epochs,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f09110-e71e-4038-8403-736908f5cca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e8490-de11-47dc-9432-4d7ecff8d46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c863c94d-82e1-4b9d-ad64-5d8a7f4e9fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1209176-f206-4c87-b563-ec6ade1bb834",
   "metadata": {},
   "source": [
    "link to tutorial for tensorboard: https://www.tensorflow.org/tensorboard/get_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "646573ae-740b-429b-bff6-5359b61a6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir =f\"runs/mobile_vgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77Bw0o1qVYuY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "77Bw0o1qVYuY",
    "outputId": "25dc9e37-5e18-4468-f46b-1f61f3e96522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/50,Train loss: 5.267, Val loss: 5.151, Val acc: 1.8%, LR: 0.000333\n",
      "Saved new best model (1.78%)\n",
      "Epoch 2/50,Train loss: 5.096, Val loss: 5.011, Val acc: 2.8%, LR: 0.000667\n",
      "Saved new best model (2.80%)\n",
      "Epoch 3/50,Train loss: 4.961, Val loss: 4.990, Val acc: 3.4%, LR: 0.001000\n",
      "Saved new best model (3.44%)\n",
      "Epoch 4/50,Train loss: 4.838, Val loss: 4.973, Val acc: 2.8%, LR: 0.000999\n",
      "Epoch 5/50,Train loss: 4.720, Val loss: 4.910, Val acc: 4.3%, LR: 0.000996\n",
      "Saved new best model (4.33%)\n",
      "Epoch 6/50,Train loss: 4.591, Val loss: 4.821, Val acc: 5.9%, LR: 0.000991\n",
      "Saved new best model (5.85%)\n",
      "Epoch 7/50,Train loss: 4.476, Val loss: 4.788, Val acc: 7.8%, LR: 0.000984\n",
      "Saved new best model (7.76%)\n",
      "Epoch 8/50,Train loss: 4.353, Val loss: 5.046, Val acc: 7.8%, LR: 0.000976\n",
      "Epoch 9/50,Train loss: 4.214, Val loss: 4.663, Val acc: 8.9%, LR: 0.000965\n",
      "Saved new best model (8.91%)\n",
      "Epoch 10/50,Train loss: 4.120, Val loss: 4.624, Val acc: 9.4%, LR: 0.000952\n",
      "Saved new best model (9.41%)\n",
      "Epoch 11/50,Train loss: 4.022, Val loss: 4.594, Val acc: 11.1%, LR: 0.000938\n",
      "Saved new best model (11.07%)\n",
      "Epoch 12/50,Train loss: 3.932, Val loss: 4.440, Val acc: 13.0%, LR: 0.000922\n",
      "Saved new best model (12.98%)\n",
      "Epoch 13/50,Train loss: 3.822, Val loss: 4.522, Val acc: 10.3%, LR: 0.000905\n",
      "Epoch 14/50,Train loss: 3.755, Val loss: 4.503, Val acc: 12.5%, LR: 0.000885\n",
      "Epoch 15/50,Train loss: 3.675, Val loss: 4.462, Val acc: 13.4%, LR: 0.000865\n",
      "Saved new best model (13.36%)\n",
      "Epoch 16/50,Train loss: 3.572, Val loss: 4.328, Val acc: 14.8%, LR: 0.000842\n",
      "Saved new best model (14.76%)\n",
      "Epoch 17/50,Train loss: 3.499, Val loss: 4.479, Val acc: 14.6%, LR: 0.000819\n",
      "Epoch 18/50,Train loss: 3.423, Val loss: 4.266, Val acc: 15.9%, LR: 0.000794\n",
      "Saved new best model (15.90%)\n",
      "Epoch 19/50,Train loss: 3.349, Val loss: 4.336, Val acc: 15.3%, LR: 0.000768\n",
      "Epoch 20/50,Train loss: 3.287, Val loss: 4.307, Val acc: 16.3%, LR: 0.000741\n",
      "Saved new best model (16.28%)\n",
      "Epoch 21/50,Train loss: 3.195, Val loss: 4.278, Val acc: 16.3%, LR: 0.000713\n",
      "Epoch 22/50,Train loss: 3.133, Val loss: 4.336, Val acc: 17.0%, LR: 0.000684\n",
      "Saved new best model (17.05%)\n",
      "Epoch 23/50,Train loss: 3.083, Val loss: 4.347, Val acc: 16.9%, LR: 0.000655\n",
      "Epoch 24/50,Train loss: 3.002, Val loss: 4.273, Val acc: 18.8%, LR: 0.000625\n",
      "Saved new best model (18.83%)\n",
      "Epoch 25/50,Train loss: 2.963, Val loss: 4.280, Val acc: 22.0%, LR: 0.000594\n",
      "Saved new best model (22.01%)\n",
      "Epoch 26/50,Train loss: 2.914, Val loss: 4.247, Val acc: 18.3%, LR: 0.000563\n",
      "Epoch 27/50,Train loss: 2.798, Val loss: 4.255, Val acc: 21.5%, LR: 0.000532\n",
      "Epoch 28/50,Train loss: 2.793, Val loss: 4.157, Val acc: 21.6%, LR: 0.000500\n",
      "Epoch 29/50,Train loss: 2.737, Val loss: 4.229, Val acc: 20.0%, LR: 0.000469\n",
      "Epoch 30/50,Train loss: 2.650, Val loss: 4.250, Val acc: 21.6%, LR: 0.000438\n",
      "Epoch 31/50,Train loss: 2.598, Val loss: 4.254, Val acc: 21.5%, LR: 0.000407\n",
      "Epoch 32/50,Train loss: 2.590, Val loss: 4.206, Val acc: 22.0%, LR: 0.000376\n",
      "Epoch 33/50,Train loss: 2.545, Val loss: 4.230, Val acc: 22.0%, LR: 0.000346\n",
      "Epoch 34/50,Train loss: 2.499, Val loss: 4.235, Val acc: 23.2%, LR: 0.000317\n",
      "Saved new best model (23.16%)\n",
      "Epoch 35/50,Train loss: 2.457, Val loss: 4.243, Val acc: 23.4%, LR: 0.000288\n",
      "Saved new best model (23.41%)\n",
      "Epoch 36/50,Train loss: 2.422, Val loss: 4.204, Val acc: 22.8%, LR: 0.000260\n",
      "Epoch 37/50,Train loss: 2.363, Val loss: 4.241, Val acc: 23.0%, LR: 0.000233\n",
      "Epoch 38/50,Train loss: 2.350, Val loss: 4.223, Val acc: 23.0%, LR: 0.000207\n",
      "Epoch 39/50,Train loss: 2.336, Val loss: 4.233, Val acc: 23.3%, LR: 0.000182\n",
      "Epoch 40/50,Train loss: 2.285, Val loss: 4.202, Val acc: 22.8%, LR: 0.000159\n",
      "Epoch 41/50,Train loss: 2.261, Val loss: 4.220, Val acc: 23.5%, LR: 0.000136\n",
      "Saved new best model (23.54%)\n",
      "Epoch 42/50,Train loss: 2.229, Val loss: 4.220, Val acc: 22.3%, LR: 0.000116\n",
      "Epoch 43/50,Train loss: 2.236, Val loss: 4.282, Val acc: 23.2%, LR: 0.000096\n",
      "Epoch 44/50,Train loss: 2.216, Val loss: 4.197, Val acc: 23.3%, LR: 0.000079\n",
      "Epoch 45/50,Train loss: 2.214, Val loss: 4.231, Val acc: 23.4%, LR: 0.000063\n",
      "Epoch 46/50,Train loss: 2.172, Val loss: 4.204, Val acc: 23.3%, LR: 0.000049\n",
      "Epoch 47/50,Train loss: 2.162, Val loss: 4.236, Val acc: 24.2%, LR: 0.000036\n",
      "Saved new best model (24.17%)\n",
      "Epoch 48/50,Train loss: 2.143, Val loss: 4.243, Val acc: 24.2%, LR: 0.000025\n",
      "Epoch 49/50,Train loss: 2.157, Val loss: 4.249, Val acc: 23.3%, LR: 0.000017\n",
      "Epoch 50/50,Train loss: 2.134, Val loss: 4.255, Val acc: 23.9%, LR: 0.000010\n",
      "Training complete, best val acc: 24.17%\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "lrs = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # warmup\n",
    "    if epoch < 3:  # warmup <3\n",
    "        warmup_lr = (epoch + 1) / 3 * 1e-3\n",
    "        optimizer.param_groups[0]['lr'] = warmup_lr\n",
    "\n",
    "    #training\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    val_acc = 100.0 * correct / total\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    # after warmup, schedular steps in\n",
    "    if epoch >= 3:\n",
    "        scheduler.step()\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    lrs.append(current_lr)\n",
    "\n",
    "    #tensorboard writing\n",
    "    writer.add_scalar(\"Loss/train\", avg_train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/val\", avg_val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/val\", val_acc, epoch)\n",
    "    writer.add_scalar(\"LR\", current_lr, epoch)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs},\"\n",
    "        f\"Train loss: {avg_train_loss:.3f}, \"\n",
    "        f\"Val loss: {avg_val_loss:.3f}, \"\n",
    "        f\"Val acc: {val_acc:.1f}%, \"\n",
    "        f\"LR: {current_lr:.6f}\"\n",
    "    )\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"mobile_vgg_eval.pth\")\n",
    "        print(f\"Saved new best model ({val_acc:.2f}%)\")\n",
    "\n",
    "print(f\"Training complete, best val acc: {best_acc:.2f}%\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b3b8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea3b3b8f",
    "outputId": "f814e730-725b-477f-ca1d-12d0de24a155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "Saved submissions.csv!\n"
     ]
    }
   ],
   "source": [
    "model = mobile_vgg(num_classes=num_classes).to(device)\n",
    "model.load_state_dict(torch.load(\"mobile_vgg.pth\", map_location=device))\n",
    "model.eval()\n",
    "print(\"Model loaded!\")\n",
    "\n",
    "# Predict\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend((preds.cpu().numpy() + 1))\n",
    "\n",
    "\n",
    "# Save\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": range(1, len(predictions) + 1),\n",
    "    \"label\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submissions.csv\", index=False)\n",
    "print(\"Saved submissions.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pdpEWl0t0-8g",
   "metadata": {
    "id": "pdpEWl0t0-8g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
